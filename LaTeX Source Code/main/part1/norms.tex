\section{Prerequisite}
\begin{definition}[Vector Norm]
    A \textit{norm} is a function $\| \cdot \|: \mathbb{C}^{m} \to \mathbb{R}$ that assigns a real-valued length to each vector. In order to conform to a reasonable notion of length, a norm must 
    satisfy the following three conditions. For all vectors $x$ and $y$ and for all scalars $\alpha \in \mathbb{C}$,
    \begin{enumerate}
        \item[(1)] $\| x \| \geq 0$ and $\| x \| = 0$ only if $x = 0$,
        \item[(2)] $\| x + y\| \leq \| x\| + \| y\|$,
        \item[(3)] $\| \alpha x \| = |\alpha| \|x\|$.
    \end{enumerate}
\end{definition}
\begin{lemma}
Given a permutation matrix $\bf{P} \in \mathcal{M}_{m \times n}$, and a vector $\bm{x} \in \mathbb{C}^{n}$, then 
$$
    \|\bm{Px} \|_p = \|\bm{x} \|_p.
$$
\begin{proof} 
By the definition of vector norm, we can get that
$$
\|\bm{x}\|_p = \begin{cases}
\left(\sum_{i=1}^{m} |x_i|^{p})^{\frac{1}{p}}\right), & 1\leq p < \infty; \\
\max_{i} \{ x_i \}, & p = \infty .
\end{cases}
$$
It is clear that $\| \bm{x} \|_p$ won't be changed after permutation of entries. Therefore, for any permutation matrix $\bm{P}$,
$$
    \|\bm{Px} \|_p  = \|\bm{x} \|_p,
$$
which is what we need to prove.
\end{proof}
\end{lemma}

\begin{corollary}
Given matrix $\bm{A} \in \mathcal{M}_{m\times n} $ and two permutation matrix $\bm{P} \in \mathcal{M}_{m \times m}, \bm{Q} \in \mathcal{M}_{n \times n}$. Then,
$$
\| \bm{PAQ}\|_{p} = \|  \bm{A} \|_{p}.
$$
\end{corollary}

\begin{proof}
    By the definition of induced norm, we can get that the LHS equals
    $$
    LHS = \|\bm{A}\|_p = \sup_{x} \frac{\| \bm{A} x\|_p}{\|x\|_p} =  \sup_{x} \frac{\|\bm{AQ} x \|_p}{\|\bm{Q} x\|_p} = \sup_{x} \frac{\|\bm{AQ} x \|_p}{\|x\|_p} = \| \bm{AQ} \|_p,
    $$
    Futhermore, the RHS equals
    $$
    RHS = \| \bm{PAQ}\|_p = \sup_{x} \frac{\|\bm{PAQ} x\|_p}{\|x\|_p} = \sup_{x} \frac{\| \bm{AQ}x \|_p}{\|x \|_p} = \| \bm{AQ}\|_p = LHS,
    $$
    which is we need to prove.
\end{proof}



\section{Solutions}
\begin{enumerate}
    \item[3.1] {
    By equation (3.3), we can get that
    $$
         \| \bm{x} \|_{\bm{W}} = \|\bm{Wx} \|,
    $$
    where $\| \cdot \|$ is a vector norm. It is clear that $\|\cdot \|_{\bm{W}}$ meets (2), (3) of the vector norm's definition. Furthermore, we assume that
    \begin{equation*}
    \bm{Wx} = \bm{0}.  \tag{$\star$}
    \end{equation*}
    }
    Since $\bm{W}$ is non-singular, $(\star)$ is true iif. $\bm{x} = \bm{0}$. Then $\| x\|_{\bm{W}} = \|\bm{Wx} \| \geq 0$, and $\| \bm{x} \|= 0 $ iif. $\| \bm{x} \| = 0$, which meets condition (1) of vector norm's definition. Hence, we can conclude that $\| \cdot \|_{\bm{W}}$ is a vector norm.

    \item[3.2] {
        Let $\lambda$ be the eigenvalue of $\bm{A}$ and $\bm{x}$ be the eigenvector w.r.t. $\lambda$, then
        \begin{equation*}
        \bm{A} x = \lambda x, \tag{$\star$}
        \end{equation*}
        where $x \neq 0$. We can concentrate m's $x$ as a matrix $\bm{X}$ with m columns, which is 
        $$
        (x, x, \cdots, x) = \bm{X} \in \mathbb{R}^{m \times n}.
        $$
        By $(\star)$, we can get that
        \begin{equation*}
            \bm{A} (x, x, \cdots, x)= \bm{A} \bm{X}=\lambda \bm{X}, \tag{$\spadesuit$}
        \end{equation*}
        Implement the norm on both sides of $(\spadesuit)$, then
        $$
        \| \lambda \bm{X} \| = | \lambda | \| \bm{X} \| = \| \bm{AX} \| \leq \| \bm{A} \| \|\bm{X} \|,
        $$
        Note that $\bm{X} \neq \bm{0}$ and hence $| \lambda | \leq \| \bm{A} \|$ for any eigenvalue $\lambda$ of $\bm{A}$. Therefore
        $$
        \rho(\bm{A}) = \max \{ \lambda \} \leq \| \bm{A} \|.
        $$
        which is exactly we want to prove.
    }   
\end{enumerate}
